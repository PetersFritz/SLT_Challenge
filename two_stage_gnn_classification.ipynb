{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CU57cvElRwdp"
      },
      "outputs": [],
      "source": [
        "#!pip install tqdm\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to download a file with a progress bar\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "\n",
        "#url = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "#output = \"glove.6B.zip\"\n",
        "\n",
        "# Download the GloVe embeddings with a progress bar\n",
        "#with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n",
        "    #urllib.request.urlretrieve(url, filename=output, reporthook=t.update_to)\n",
        "\n",
        "\n",
        "# Unzip the downloaded file\n",
        "#with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    #zip_ref.extractall()\n",
        "\n",
        "# Ensure gensim is installed\n",
        "#!pip install gensim\n",
        "\n",
        "# Import KeyedVectors from gensim and load the word vectors\n",
        "from gensim.models import KeyedVectors\n",
        "word_vectors = KeyedVectors.load_word2vec_format('glove.6B.50d.txt', binary=False, no_header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WTz7VpJcWx_q",
        "outputId": "8ac0bbb6-3780-4792-8916-eb38c8bad77c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1b5a3c6e7d0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install ipdb\n",
        "#!pip install torch torch-geometric\n",
        "#!pip install pandas\n",
        "#!pip install scikit-learn\n",
        "#!pip install matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from collections import defaultdict, Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipdb\n",
        "\n",
        "\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch.optim import Adam\n",
        "from torch.nn.functional import cross_entropy\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score, roc_auc_score, r2_score, mean_squared_error\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uhx3pQcEtI8I",
        "outputId": "1f7d117c-aa5a-4650-ca97-28939a41e2e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!unzip drive/MyDrive/slt_challenge/transcripts_outputFiles.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q_bg9DDdUdat"
      },
      "outputs": [],
      "source": [
        "def load_graph_info(nodes_degree_txt, nodes_edges_txt):\n",
        "  nodes_features = defaultdict(dict)\n",
        "  edges = []\n",
        "  with open(nodes_degree_txt, 'r') as nodes_degree_file, open(nodes_edges_txt, 'r') as nodes_edges_file:\n",
        "      reading_nodes, reading_edges = False, False\n",
        "\n",
        "      for line in nodes_edges_file:\n",
        "          line = line.strip()\n",
        "          if (not line) or line.startswith(\"id*int\") or line.startswith(\"source*int\"):\n",
        "              continue\n",
        "\n",
        "          if line.startswith(\"*Nodes\"):\n",
        "              # start reading node info\n",
        "              reading_nodes = True\n",
        "              reading_edges = False\n",
        "          elif line.startswith(\"*DirectedEdges\"):\n",
        "              # start reading edge info\n",
        "              reading_nodes = False\n",
        "              reading_edges = True\n",
        "\n",
        "          elif reading_nodes:\n",
        "            # parse node info\n",
        "              parts = line.split(\" \", 2)\n",
        "              node_id = int(parts[0])\n",
        "              label = parts[1].strip('\"')\n",
        "              nodes_features[node_id]['label'] = label\n",
        "\n",
        "\n",
        "          elif reading_edges:\n",
        "            # parse edge info\n",
        "              parts = line.split()\n",
        "              source = int(parts[0])\n",
        "              target = int(parts[1])\n",
        "              edges.append((source, target))\n",
        "\n",
        "      for line in nodes_degree_file:\n",
        "        line = line.strip()\n",
        "        if (not line) or (not line.startswith(\"Node Degree\")):\n",
        "          parts = line.split()\n",
        "          node_id = int(parts[0])\n",
        "          degree = parts[1].strip('\"')\n",
        "          nodes_features[node_id]['degree'] = degree\n",
        "\n",
        "      # print(len(nodes_features), len(edges))\n",
        "      return nodes_features, edges\n",
        "\n",
        "\n",
        "def get_word_embedding(word, embedding_dim=50):\n",
        "    try:\n",
        "        return torch.tensor(word_vectors[word], dtype=torch.float)\n",
        "    except KeyError:\n",
        "        # for words not in the vocabulary, use a zero vector\n",
        "        # print('WARNING: word not in the vocabulary: ', word)\n",
        "        return torch.zeros(embedding_dim)\n",
        "\n",
        "\n",
        "def prep_data_for_gnn(nodes_features, edges):\n",
        "    # mapping from node ID to index\n",
        "    node_id_to_index = {node_id: i for i, node_id in enumerate(nodes_features.keys())}\n",
        "\n",
        "    # create node features: node degrees and word embeddings)\n",
        "    features = []\n",
        "    for node_id in nodes_features.keys():\n",
        "        node_label = nodes_features[node_id]['label']\n",
        "        node_embeddings = get_word_embedding(node_label)\n",
        "        # print(node_id,nodes_features[node_id]['degree'])\n",
        "        # new_value = torch.tensor([15], dtype=torch.int64)\n",
        "        # tensor = torch.cat((node_embeddings, new_value))\n",
        "\n",
        "        features.append(node_embeddings)\n",
        "    #pca = PCA(n_components=pca_components)\n",
        "    #reduced_features = pca.fit_transform(features)  \n",
        "    #x = torch.tensor(reduced_features, dtype=torch.float32) \n",
        "    x = torch.stack(features) \n",
        "\n",
        "    # create edge index tensor\n",
        "    edge_index = torch.tensor(\n",
        "        [[node_id_to_index[src], node_id_to_index[dst]] for src, dst in edges],\n",
        "        dtype=torch.long,\n",
        "    ).t().contiguous()\n",
        "    return x, edge_index\n",
        "\n",
        "\n",
        "def get_datalist(id_list, label_list, transcript_folder):\n",
        "  \"\"\"\n",
        "  returns a list of Data objects\n",
        "  \"\"\"\n",
        "  data_list = []\n",
        "  id_label_list = [(id, label) for id, label in zip(id_list, label_list)]\n",
        "  for id, label in id_label_list:\n",
        "    filepath = os.path.join(transcript_folder, id)\n",
        "    nodes_features, edges = load_graph_info(f'{filepath}_dir_nodes_degree.txt', f'{filepath}_dir_nodes_edges.txt')\n",
        "    x, edge_index = prep_data_for_gnn(nodes_features, edges)\n",
        "    graph_data = Data(x=x, edge_index=edge_index, y=torch.tensor([label], dtype=torch.long))\n",
        "    data_list.append(graph_data)\n",
        "  return data_list\n",
        "\n",
        "\n",
        "def get_dataloader(data_list, batch_size=None):\n",
        "  if not batch_size:\n",
        "    batch_size = len(data_list)\n",
        "    print('Setting batch size to ', batch_size)\n",
        "  return DataLoader(data_list, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def calculate_class_weights(labels):\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight = 'balanced',\n",
        "        classes = np.unique(labels),\n",
        "        y = labels)\n",
        "   \n",
        "    return torch.tensor(class_weights, dtype=torch.float)\n",
        "   \n",
        "\n",
        "\n",
        "class GNNClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GNNClassifier, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "        self.fc = Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_gnn(train_datalist, train_batch_size=None, hidden_dim=64, lr=0.01, epoches=250, class_weights=None, num_classes = 2):\n",
        "  torch.manual_seed(42)\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  train_dataloader = get_dataloader(train_datalist, batch_size=train_batch_size)\n",
        "\n",
        "  num_node_features = next(iter(train_dataloader)).x.size(1)\n",
        "\n",
        "  model = GNNClassifier(input_dim=num_node_features, hidden_dim=hidden_dim, output_dim=num_classes).to(device)\n",
        "  optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  if class_weights is not None:\n",
        "      class_weights = class_weights.to(device) \n",
        "  loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "  for epoch in range(epoches):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "\n",
        "      for batch in train_dataloader:\n",
        "          batch = batch.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          out = model(batch)\n",
        "          loss = loss_fn(out, batch.y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "\n",
        "      if epoch % 50 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.5f}')\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def eval_gnn(model, eval_datalist, stage_labels=None, print_results=True, batch_size=None):\n",
        "    model.eval()\n",
        "    logits_list, pred_list, y_list = [], [], []\n",
        "    eval_dataloader = get_dataloader(eval_datalist, batch_size=batch_size)\n",
        "    for batch in eval_dataloader:\n",
        "        logits = model(batch)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        logits_list.append(logits)\n",
        "        pred_list.append(pred)\n",
        "        y_list.append(batch.y)\n",
        "    # concatenate data from all batches\n",
        "    logits_all = torch.cat(logits_list, dim=0)\n",
        "    pred_all = torch.cat(pred_list, dim=0)\n",
        "    y_all = torch.cat(y_list, dim=0)\n",
        "    # get metrics\n",
        "    results, disp = calc_metrics(y_all, pred_all, display_labels=stage_labels)\n",
        "    return logits_all, pred_all, results, disp\n",
        "\n",
        "def calc_metrics(actual_labels, pred_vals, display_labels=None, print_results=True):\n",
        "    results = {\n",
        "        'accuracy': accuracy_score(actual_labels, pred_vals),\n",
        "        'f1': f1_score(actual_labels, pred_vals, average='macro'),\n",
        "        'precision': precision_score(actual_labels, pred_vals, average='macro'),\n",
        "        'recall': recall_score(actual_labels, pred_vals, average='macro')\n",
        "    }\n",
        "\n",
        "    cm = confusion_matrix(actual_labels, pred_vals)\n",
        "\n",
        "    # Get only the unique classes present in the actual predictions\n",
        "    unique_classes = np.unique(np.concatenate([actual_labels, pred_vals]))  \n",
        "    if display_labels is None:\n",
        "        display_labels = [str(label) for label in unique_classes]  # Ensure matching labels\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
        "\n",
        "    if print_results:\n",
        "        for metric, value in results.items():\n",
        "            print(f'{metric}: {value:.3f}')\n",
        "        disp.plot()\n",
        "        plt.show()\n",
        "\n",
        "    return results, disp\n",
        "\n",
        "\n",
        "class NNMetaModel(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "      super().__init__()\n",
        "      self.fc1 = Linear(input_dim, hidden_dim)\n",
        "      self.fc2 = Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x = x.relu()\n",
        "      x = self.fc2(x)\n",
        "      return x\n",
        "\n",
        "def train_nn_metamodel(features, labels, epochs=50, hidden_dim=32, lr=0.01, n_tasks=3):\n",
        "    num_classes = len(torch.unique(labels))\n",
        "    input_dim = features.shape[1]\n",
        "    model = NNMetaModel(input_dim, hidden_dim=hidden_dim, output_dim=num_classes)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(features)\n",
        "        loss = cross_entropy(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "_o2-EhsgUfpz",
        "outputId": "7599ccad-dbc9-433b-eeca-f219803fb777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 0:\n",
            "\n",
            "    train set for base model: 100 samples; label count: Counter({0: 52, 1: 38, 2: 10}),\n",
            "    train set for meta model: 25 samples; label count: Counter({0: 13, 1: 10, 2: 2}),\n",
            "    dev set for meta model: 32 samples; label count: Counter({0: 17, 1: 11, 2: 4})\n",
            "----------- Task: CTD -----------\n",
            "Training base model train set + meta model train set...\n",
            "Setting batch size to  125\n",
            "Epoch 0, Loss: 0.69260\n",
            "Epoch 50, Loss: 0.10494\n",
            "Epoch 100, Loss: 0.00087\n",
            "Epoch 150, Loss: 0.00040\n",
            "Epoch 200, Loss: 0.00024\n",
            "Validating on meta model dev set...\n",
            "Setting batch size to  32\n",
            "accuracy: 0.844\n",
            "f1: 0.458\n",
            "precision: 0.435\n",
            "recall: 0.482\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'torch.Tensor'>\n",
            "Training base model for Healthy vs. MCI (Stage 2)...\n",
            "Setting batch size to  113\n",
            "Epoch 0, Loss: 0.69673\n",
            "Epoch 50, Loss: 0.41367\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     82\u001b[39m combined_labels_stg2 = np.concatenate([base_train_label_stage2, ensemble_train_label_stage2])\n\u001b[32m     83\u001b[39m class_weights_stg2 = calculate_class_weights(combined_labels_stg2)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m trained_gnn_stage2 = \u001b[43mtrain_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhealthy_train_datalist\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mhealthy_ensemble_train_datalist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights_stg2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mValidating Stage 2 model on meta model dev set...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Get samples and labels for predicted healthy individuals in stage 1\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 149\u001b[39m, in \u001b[36mtrain_gnn\u001b[39m\u001b[34m(train_datalist, train_batch_size, hidden_dim, lr, epoches, class_weights, num_classes)\u001b[39m\n\u001b[32m    146\u001b[39m model.train()\n\u001b[32m    147\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Student\\Documents\\phd_work\\SLT_challenge\\.conda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Student\\Documents\\phd_work\\SLT_challenge\\.conda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Student\\Documents\\phd_work\\SLT_challenge\\.conda\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Student\\Documents\\phd_work\\SLT_challenge\\.conda\\Lib\\site-packages\\torch_geometric\\loader\\dataloader.py:27\u001b[39m, in \u001b[36mCollater.__call__\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     25\u001b[39m elem = batch[\u001b[32m0\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch.Tensor):\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Student\\Documents\\phd_work\\SLT_challenge\\.conda\\Lib\\site-packages\\torch_geometric\\data\\batch.py:97\u001b[39m, in \u001b[36mBatch.from_data_list\u001b[39m\u001b[34m(cls, data_list, follow_batch, exclude_keys)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_data_list\u001b[39m(\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     88\u001b[39m ) -> Self:\n\u001b[32m     89\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     batch, slice_dict, inc_dict = \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     batch._num_graphs = \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    107\u001b[39m     batch._slice_dict = slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Student\\Documents\\phd_work\\SLT_challenge\\.conda\\Lib\\site-packages\\torch_geometric\\data\\collate.py:109\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m value, slices, incs = \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value.is_cuda:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Student\\Documents\\phd_work\\SLT_challenge\\.conda\\Lib\\site-packages\\torch_geometric\\data\\collate.py:178\u001b[39m, in \u001b[36m_collate\u001b[39m\u001b[34m(key, values, data_list, stores, increment)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    176\u001b[39m     incs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(elem, \u001b[33m'\u001b[39m\u001b[33mis_nested\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    179\u001b[39m     tensors = []\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m nested_tensor \u001b[38;5;129;01min\u001b[39;00m values:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Config Experiment\n",
        "config = {\n",
        "    \"tasks\": ['CTD', 'SFT', 'PFT'],\n",
        "    \"num_folds\": 5,\n",
        "    \"random_state\": 42,\n",
        "    \"label_mapping_stage1\": {0: 0, 1: 0, 2: 1},\n",
        "    \"label_mapping_stage2\": {'HC': 0, 'MCI': 1},\n",
        "    \"label_mapping_non_cascaded\": {'HC': 0, 'MCI': 1, 'Dementia': 2}\n",
        "}\n",
        "\n",
        "# Load metadata\n",
        "metadata = pd.read_csv(\"PROCESS_METADATA_ALL.csv\")\n",
        "metadata = metadata.sample(frac=1, random_state=config['random_state'], ignore_index=False)\n",
        "metadata['diagnosis_coded'] = metadata['diagnosis'].map(config['label_mapping_non_cascaded'])\n",
        "df_traindev = metadata[metadata['Tr/Tt/Dv'].isin(['train', 'dev'])]\n",
        "id_traindev, label_traindev = df_traindev['anyon_IDs'], df_traindev['diagnosis_coded']\n",
        "\n",
        "skf = StratifiedKFold(n_splits=config[\"num_folds\"], shuffle=True, random_state=config['random_state'])\n",
        "\n",
        "all_preds = defaultdict(lambda: {\"Stage1\": [], \"Stage2\": [], \"Overall\": []})\n",
        "all_trues = defaultdict(lambda: {\"Stage1\": [], \"Stage2\": [], \"Overall\": []})\n",
        "\n",
        "# Split data into train and dev sets for each fold\n",
        "for fold_index, (train_index, dev_index) in enumerate(skf.split(id_traindev, label_traindev)):\n",
        "    print(f\"Fold {fold_index}:\")\n",
        "    base_train_id, ensemble_train_id, base_train_label, ensemble_train_label = train_test_split(id_traindev[train_index], label_traindev[train_index],\n",
        "                                                        stratify=label_traindev[train_index],\n",
        "                                                        test_size=0.2)\n",
        "    \n",
        "    print(f'''\n",
        "    train set for base model: {len(base_train_label)} samples; label count: {Counter(base_train_label)},\n",
        "    train set for meta model: {len(ensemble_train_label)} samples; label count: {Counter(ensemble_train_label)},\n",
        "    dev set for meta model: {len(label_traindev[dev_index])} samples; label count: {Counter(label_traindev[dev_index])}''')\n",
        "\n",
        "    # Prepare labels for stage 1 and stage 2\n",
        "    base_train_label_stage1 = base_train_label.map(config['label_mapping_stage1'])\n",
        "    ensemble_train_label_stage1 = ensemble_train_label.map(config['label_mapping_stage1'])\n",
        "    label_traindev_stage1_dev = label_traindev[dev_index].map(config['label_mapping_stage1'])\n",
        "\n",
        "    base_train_label_stage2 = base_train_label[base_train_label != 2]\n",
        "    ensemble_train_label_stage2 = ensemble_train_label[ensemble_train_label != 2]\n",
        "    label_traindev_stage2_dev = label_traindev[dev_index][label_traindev[dev_index] != 2]\n",
        "\n",
        "    # Identify data samples for stage 2\n",
        "    base_train_id_stage2 = base_train_id[base_train_label != 2]\n",
        "    ensemble_train_id_stage2 = ensemble_train_id[ensemble_train_label != 2]\n",
        "    id_traindev_stage2_dev = id_traindev[dev_index][label_traindev[dev_index] != 2]\n",
        "\n",
        "    # Train and evaluate models for each task\n",
        "    for task in config['tasks']:\n",
        "        print(f'----------- Task: {task} -----------')\n",
        "        transcript_folder = os.path.join(\"transcripts_outputFiles\", f\"{task}_outputFiles\")\n",
        "        if not os.path.exists(transcript_folder):\n",
        "            os.makedirs(transcript_folder)\n",
        "\n",
        "        # Prepare data, calculate class weights, and train models for stage 1\n",
        "        base_train_datalist_stage1 = get_datalist(base_train_id, base_train_label_stage1, transcript_folder)\n",
        "        ensemble_train_datalist_stage1 = get_datalist(ensemble_train_id, ensemble_train_label_stage1, transcript_folder)\n",
        "        ensemble_dev_datalist_stage1 = get_datalist(id_traindev[dev_index], label_traindev_stage1_dev[dev_index], transcript_folder)\n",
        "\n",
        "        combined_labels_stg1 = np.concatenate([base_train_label_stage1, ensemble_train_label_stage1])\n",
        "        class_weights_stg1 = calculate_class_weights(combined_labels_stg1)\n",
        "\n",
        "        print('Training base model train set + meta model train set...')\n",
        "        trained_gnn_stage1 = train_gnn(base_train_datalist_stage1 + ensemble_train_datalist_stage1, class_weights=class_weights_stg1)\n",
        "        \n",
        "        print('Validating on meta model dev set...')\n",
        "        _, task_pred_ensemble_validation, _, _ = eval_gnn(trained_gnn_stage1, ensemble_dev_datalist_stage1, stage_labels= ['Non-Dementia', 'Dementia'], print_results=False)\n",
        "        print(type(label_traindev[dev_index]))\n",
        "        print(type(task_pred_ensemble_validation))\n",
        "        all_preds[task][\"Stage1\"].extend(task_pred_ensemble_validation.tolist())\n",
        "        all_trues[task][\"Stage1\"].extend(label_traindev_stage1_dev.tolist())\n",
        "\n",
        "        # Prepare data, calculate class weights, and train models for stage 2\n",
        "        healthy_train_datalist = get_datalist(base_train_id_stage2, base_train_label_stage2, transcript_folder)\n",
        "        healthy_ensemble_train_datalist = get_datalist(ensemble_train_id_stage2, ensemble_train_label_stage2, transcript_folder)\n",
        "\n",
        "        print('Training base model for Healthy vs. MCI (Stage 2)...')\n",
        "        combined_labels_stg2 = np.concatenate([base_train_label_stage2, ensemble_train_label_stage2])\n",
        "        class_weights_stg2 = calculate_class_weights(combined_labels_stg2)\n",
        "        trained_gnn_stage2 = train_gnn(healthy_train_datalist + healthy_ensemble_train_datalist, class_weights=class_weights_stg2)\n",
        "\n",
        "        print('Validating Stage 2 model on meta model dev set...')\n",
        "        # Get samples and labels for predicted healthy individuals in stage 1\n",
        "        predicted_healthy_dev_indices = [i for i, pred in enumerate(task_pred_ensemble_validation) if pred == 0]\n",
        "    \n",
        "        predicted_healthy_dev_ids = []\n",
        "        predicted_healthy_dev_labels = []\n",
        "\n",
        "        dementia_misclassifications_dev = 0\n",
        "\n",
        "        for i in predicted_healthy_dev_indices:\n",
        "            label = label_traindev[dev_index].iloc[i]\n",
        "            if label != 2:\n",
        "                predicted_healthy_dev_ids.append(id_traindev[dev_index].iloc[i])\n",
        "                predicted_healthy_dev_labels.append(label)\n",
        "            else:\n",
        "                dementia_misclassifications_dev += 1\n",
        "\n",
        "        predicted_healthy_dev_datalist = get_datalist(predicted_healthy_dev_ids, predicted_healthy_dev_labels, transcript_folder)\n",
        "\n",
        "        _, task_pred_stage2_dev, results_dict, _ = eval_gnn(trained_gnn_stage2, predicted_healthy_dev_datalist, stage_labels=['HC', 'MCI'])\n",
        "\n",
        "        print(type(predicted_healthy_dev_ids))\n",
        "        print(type(task_pred_stage2_dev))\n",
        "        task_pred_stage2_dev = task_pred_stage2_dev if isinstance(task_pred_stage2_dev, list) else task_pred_stage2_dev.tolist()\n",
        "        \n",
        "        all_preds[task][\"Stage2\"].extend(task_pred_stage2_dev)\n",
        "        all_trues[task][\"Stage2\"].extend(predicted_healthy_dev_labels)\n",
        "\n",
        "        # Calculate overall performance on ensemble development set\n",
        "\n",
        "        combined_predictions_ensemble_dev = []\n",
        "\n",
        "        stage2_predictions_dev_dict = dict(zip(predicted_healthy_dev_ids, task_pred_stage2_dev))\n",
        "\n",
        "        for i, id_value in enumerate(id_traindev[dev_index]):\n",
        "            if task_pred_ensemble_validation[i] == 0: \n",
        "                if id_value in stage2_predictions_dev_dict:\n",
        "                    if stage2_predictions_dev_dict[id_value] == 0:\n",
        "                        combined_predictions_ensemble_dev.append('HC')\n",
        "                    else:\n",
        "                        combined_predictions_ensemble_dev.append('MCI')\n",
        "                else:\n",
        "                    combined_predictions_ensemble_dev.append('Unknown_Non_Dementia')\n",
        "            else:  # Stage 1 predicted Dementia\n",
        "                combined_predictions_ensemble_dev.append('Dementia')\n",
        "\n",
        "        actual_labels_ensemble_dev = label_traindev[dev_index].map({0: 'HC', 1: 'MCI', 2: 'Dementia'})\n",
        "\n",
        "        all_preds[task][\"Overall\"].extend(combined_predictions_ensemble_dev)\n",
        "        all_trues[task][\"Overall\"].extend(actual_labels_ensemble_dev.tolist())\n",
        "\n",
        "# Print results of GNN for each task and stage\n",
        "\n",
        "for task in all_preds.keys():\n",
        "    for stages in all_preds[task].keys():\n",
        "        print(f'\\n----------- Task: {task} -----------\\n-----------{stages} -----------')\n",
        "        print(classification_report(all_trues[task][stages], all_preds[task][stages]))\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
